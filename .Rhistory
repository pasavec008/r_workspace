shapiro.test(data2_1)
# Priklad 2
#' Najskor zistime, ci su data normalne rozdelene pomocou Shapiro Wilkovho
#' testu
shapiro.test(data2_1$korozia)
shapiro.test(data2_2$korozia)
shapiro.test(data2_3$korozia)
# Obojstranny interval spolahlivosti
t.test(data2_3$korozia)$conf.int
# Dalej pracujeme len s pripadom 3, kedze je ako jediny normalne rozdeleny
# Obojstranny interval spolahlivosti
t.test(data2_3$korozia)$conf.int
# Dalej pracujeme len s pripadom 3, kedze je ako jediny normalne rozdeleny
# Obojstranny interval spolahlivosti
t.test(data2_3$korozia, conf.level = 0.9)$conf.int
#' Interval spolahlivosti pre disperziu
varTest(data2_3$korozia)$conf.int
#' Interval spolahlivosti pre disperziu
varTest(data2_3$korozia, conf.level = 0.9)$conf.int
#' Kedze mame normalne rozdelenie len pri pripade 3, tak budeme
#' pracovat len s nim
# Priklad 5 ANOVA
#' Najprv musime overit podmienky ci mozem robit ANOVA
tapply(data2$korozia, data2$miesto, shapiro.test)
h
#' Zistili sme, ze data nie su normalne rozdelene vo vsetkych skupinach
#' teda nemozeme robit ANOVA, ale pouzijeme vhodny neparametricky test
#' Pouzijeme Kruskal Wallisov test
#' Najskor musime data skupin dat do faktorov
data2$miesto <- as.factor(data2$miesto)
kruskal.test(data2$korozia, data2$miesto)
#' P hodnota nam vysla > 0.05, takze nezamietame nulovu hypotezu
#' o rovnosti merani .. aby sme si boli isty, mozeme sa pozriet aj
#' na vysledok dunn testu, ktory by nam mal dat rovnake vysledky, a
#' teda ze sa merania nelisia
dunn.test(data2$korozia, data2$miesto, altp = T, list = T)
#' P hodnota nam vysla > 0.05, takze nezamietame nulovu hypotezu
#' o rovnosti merani .. aby sme si boli isty, mozeme sa pozriet aj
#' na vysledok dunn testu, ktory by nam mal dat rovnake vysledky, a
#' teda ze sa merania nelisia
library('dunn.test')
dunn.test(data2$korozia, data2$miesto, altp = T, list = T)
#' Vidime, ze vsetky hodnoty su vacsie ako 0.05, teda ziadne
#' z merani sa nam nelisia .. mozeme si pozriet aj ako vyzeraju grafy
boxplot(data2$korozia~miesto)
#' Vidime, ze vsetky hodnoty su vacsie ako 0.05, teda ziadne
#' z merani sa nam nelisia .. mozeme si pozriet aj ako vyzeraju grafy
boxplot(data2$korozia)
#' Vidime, ze vsetky hodnoty su vacsie ako 0.05, teda ziadne
#' z merani sa nam nelisia .. mozeme si pozriet aj ako vyzeraju grafy
boxplot(data2$korozia~data2$miesto)
vioplot(data2$korozia~data2$miesto)
#' P hodnota nam vysla > 0.05, takze nezamietame nulovu hypotezu
#' o rovnosti merani .. aby sme si boli isty, mozeme sa pozriet aj
#' na vysledok dunn testu, ktory by nam mal dat rovnake vysledky, a
#' teda ze sa merania nelisia
dn <- dunn.test(data2$korozia, data2$miesto, altp = T, list = T)
#' Vidime, ze vsetky hodnoty su vacsie ako 0.05, teda ziadne
#' z merani sa nam nelisia .. mozeme si pozriet aj ako vyzeraju grafy
plot(dn)
#' P hodnota nam vysla > 0.05, takze nezamietame nulovu hypotezu
#' o rovnosti merani .. aby sme si boli isty, mozeme sa pozriet aj
#' na vysledok dunn testu, ktory by nam mal dat rovnake vysledky, a
#' teda ze sa merania nelisia
dunn.test(data2$korozia, data2$miesto, altp = T, list = T)
#' Vidime, ze vsetky hodnoty su vacsie ako 0.05, teda ziadne
#' z merani sa nam nelisia .. mozeme si pozriet aj ako vyzeraju grafy
boxplot(data2$korozia~data2$miesto)
vioplot(data2$korozia~data2$miesto)
data2
# Priklad 5 ANOVA
#' Najprv musime overit podmienky ci mozem robit ANOVA
tapply(data2$korozia, data2$miesto, shapiro.test)
view(data2)
# Priklad 3
#' Pracujeme s celou datovou mnozinou (data2)
#' Stanovime si hypotezy:
#' H0: Novy sposob upravy nema lepsie vysledky ako stary sposob upravy.
#' HA: Novy sposob upravy ma lepsie vysledky ako stary sposob upravy.
#' Test pre strednu hodnotu
ZTest(data2, mu = 0.11, sd_pop = 0.03)
# Priklad 3
#' Pracujeme s celou datovou mnozinou (data2)
#' Stanovime si hypotezy:
#' H0: Novy sposob upravy nema lepsie vysledky ako stary sposob upravy.
#' HA: Novy sposob upravy ma lepsie vysledky ako stary sposob upravy.
#' Test pre strednu hodnotu
data2$miesto <- as.integer(data2$miest)
# Priklad 3
#' Pracujeme s celou datovou mnozinou (data2)
#' Stanovime si hypotezy:
#' H0: Novy sposob upravy nema lepsie vysledky ako stary sposob upravy.
#' HA: Novy sposob upravy ma lepsie vysledky ako stary sposob upravy.
#' Test pre strednu hodnotu
data2$miesto <- as.integer(data2$miesto)
ZTest(data2, mu = 0.11, sd_pop = 0.03)
# Priklad 3
#' Pracujeme s celou datovou mnozinou (data2)
#' Stanovime si hypotezy:
#' H0: Novy sposob upravy nema lepsie vysledky ako stary sposob upravy.
#' HA: Novy sposob upravy ma lepsie vysledky ako stary sposob upravy.
#' Test normalneho rozdelenia pre celu mnozinu
shapiro.test(data2$korozia)
ZTest(data2$korozia, mu = 0.11, sd_pop = 0.03)
ZTest(data2$korozia, mu = 0.11, sd_pop = 0.03, alternative = 'lesser')
ZTest(data2$korozia, mu = 0.11, sd_pop = 0.03, alternative = 'less')
ZTest(data2$korozia, mu = 0.11, sd_pop = 0.03, alternative = 'less')$p.value
data2$korozia
mean(data2$korozia)
ZTest(data2$korozia, mu = 0.11, sd_pop = 0.03, alternative = 'less')$p.value
ZTest(data2$korozia, mu = 0.11, sd_pop = 0.03, alternative = 'greater')$p.value
ZTest(data2$korozia, mu = 0.11, sd_pop = 0.03, alternative = 'greater')
ZTest(data2$korozia, mu = 0.11, sd_pop = 0.03, alternative = 'less')
ZTest(data2$korozia, mu = 0.11, sd_pop = 0.03, alternative = 'less')$p.value
#' p hodnota nam vysla vacsia ako 0.05, takze nezamietame nulovu hypotezu,
#' ze novy sposob upravy nema lepsie vysledky ako stary .. lahka kontrola je,
#' ze mean noveho sposobu je vacsi ako 0.11:
mean(data2$korozia)
#' Test pre disperziu
#' H0: disperzia = 0.03
#' H1: disperzia != 0.03
varTest(data2$korozia, sigma.squared = 0.03^2)$p.value
#' p hodnota je 0, takze odmietame nulovu hypotezu, teda plati alternativna,
#' ze disperzia sa nerovna 0.03 .. mozeme znovu skontrolovat manualnym
#' poctom
sd(data2$korozia)
#' Tvrdenie o disperzii teda nie je pravdive, ideme spravit vhodny test
#' pre strednu hodnotu
t.test(data2$korozia, mu = 0.11, alternative = 'less')$p.value
# Priklad 4
#' Na test nahodnosti pouzijeme runs test
#' H0: nahodne data
#' HA: nenahodne data
runs.test(data2$korozia, plot = T)
#' Kedze nam vysla p hodnota < 0.05, tak zamietame nulovu hypotezu
#' a berieme alternativnu, teda ze data nie su nahodne
#' Neparametricky test pre ulohu 3, teda hypotezy ostavaju nasledovne:
#' H0: Novy sposob upravy nema lepsie vysledky ako stary sposob upravy. >= 11%
#' HA: Novy sposob upravy ma lepsie vysledky ako stary sposob upravy. < 11%
#' Pouzijeme Wilcoxonov test
wilcox.test(data2$korozia, mu = 0.11, alternative = 'less')$p.value
#' Kedze nam vysla p hodnota < 0.05, tak zamietame nulovu hypotezu
#' a berieme alternativnu, teda ze data nie su nahodne
#' Neparametricky test pre ulohu 3, teda hypotezy ostavaju nasledovne:
#' H0: Novy sposob upravy nema lepsie vysledky ako stary sposob upravy. >= 11%
#' HA: Novy sposob upravy ma lepsie vysledky ako stary sposob upravy. < 11%
#' Pouzijeme Wilcoxonov test
wilcox.test(data2$korozia, mu = 0.11, alternative = 'less')
#' Priklad 4
#' Na test nahodnosti pouzijeme runs test
#' H0: nahodne data
#' HA: nenahodne data
runs.test(data2$korozia, plot = T)
#' Priklad 4
#' Na test nahodnosti pouzijeme runs test
#' H0: nahodne data
#' HA: nenahodne data
runs.test(data2$korozia, plot = T)
library(latexpdf)
x <- c(160, 250, 320, 500, 750, 900, 1000, 1500, 2000)
y <- c(789, 800, 851, 874, 1193, 1200, 1335, 1704, 2073)
x <- c(160, 250, 320, 500, 750, 900, 1000, 1500, 2000)
y <- c(789, 800, 851, 874, 1193, 1200, 1335, 1704, 2073)
korelacie <- function(x, y){c('Pearson' = cor(x, y),
'Kendall' = cor(x, y, method = 'kendall'),
'Spearman' = cor(x, y, method = 'spearman'))}
korelacie
x <- c(160, 250, 320, 500, 750, 900, 1000, 1500, 2000)
y <- c(789, 800, 851, 874, 1193, 1200, 1335, 1704, 2073)
korelacie <- function(x, y){c('Pearson' = cor(x, y),
'Kendall' = cor(x, y, method = 'kendall'),
'Spearman' = cor(x, y, method = 'spearman'))}
korelacie
korelacie(x, y)
plot(x, y, type = 'b', xlab = 'kapacita', ylab = 'cena', col = 'blue')
lm1 <- lm(y~x)
lm1 <- lm(y~x)
lm1
summary(lm1)
abline(lm1)
#' ak ho prenosbime 100%, tak vieme na kolko % vysvetluje nas model
#' spravanie sa dat.
#' Posledny riadok F statistika pre ANOVA test, nulova hypoteza je, ze
#' Y (zavisla premenna) staci popisat nejakou konstantou, teda nie nasim
#' modelom. V poslednom riadku je aj P hodnota, ak P hodnota je mensia
#' ako 0.05, zamietam hypotezu H0 a teda regresny model je vhodny.
#' Ak mame k dispozicii viac modelov, tak na vyber najlepsieho sluzia
#' hodnoty informacnych kriterii AIC, BIC. Pomocou nich sa vyberie
#' optimalny model, ktory nie je preparametrizovany (penale za velky
#' pocet parametrov) a ani nedoparametrizovany (penale za velku disperziu)
AIC(lm1)
BIC(lm1)
#' porovnajme s modelom y = bx
lm2 <- lm(y~0+x)
AIC(lm1, lm2)
#' Dalsie charakteristiky
lm1$coefficients
lm1$fitted.values
lm1$residuals
plot(lm1$residuals, type = 'b')
##################################
#' Prikald v 10 vzdialenostiach xi sa merala velkost priehybu zatazenia
#' dosky yi, vysledky su dane, prelozte vhodnu regresnu krivku
xx <- 1:10
yy <- c(2.1299,2.1532,2.1611,2.151,2.1282,2.0807,
2.0266,1.9594,1.8759,1.7723 )
plot(xx, yy, type = 'b', xlab = 'vzdialenost', ylab = 'priehyb')
plot(xx, yy, type = 'b', xlab = 'vzdialenost', ylab = 'priehyb', col = 'green')
plot(xx, yy, type = 'b', xlab = 'vzdialenost', ylab = 'priehyb', col = 'red')
plot(xx, yy, type = 'b', xlab = 'vzdialenost', ylab = 'priehyb', col = 'purple')
#' prelozime kvadraticku funkciu, vyhodnotime kvalitu modelu, mozeme
#' vykreslit aj rezidualy
lm3 <- lm(yy~poly(xx, 2))
lines(lm3)
lines(lm3$fitted.values)
lines(lm3$fitted.values, type = 'b', col = 'red')
summary(lm3)
#' Kazda z bazovych funkcii patri do mnoziny bazovych funkcii, zamietame
#' hypotezu, ze koeficienty pri funkciach su nulove, odhad smerodajnej
#' odchylky je minimalny, koeficienty determinacie su skoro jedna - kvalitny
#' model.
#' ANOVA test o vhodnosti modelu ako celku, zamietame hypotezu, ze model
#' nema zmysel
#' Vykreslime rezidualy
lm3$residuals
plot(lm3$residuals)
plot(lm3$residuals, type = 'b')
library(randtests)
turning.point.test(lm3$residuals)
h <- c(0,270,840,1452,2116,3203)
p <- c(100000,96974,90263,83553,76842,66842)
h <- c(0,270,840,1452,2116,3203)
p <- c(100000,96974,90263,83553,76842,66842)
korelacie(h, p)
plot(h, p, type = 'b', xlab = 'vyska', ylab = 'tlak')
#' regresia po transformacii dat
lm4
#' regresia po transformacii dat
lm4 <- lm(log(y)~x)
summary(lm4)
#' regresia po transformacii dat
lm4 <- lm(log(p)~h)
summary(lm4)
#' Spatna transformacia pre parametre
a <- exp(lm4$coefficients[1])
a
b <- lm4$coefficients[2]
b
pp <- a * exp(b*h)
pp
lines(h, pp, type = 'b', col = 'red')
zz <- c(112,140,143,120,196,294,513,518,430,274,
255,236,256,222,213)
xx <- c(0.3,0.49,0.61,0.49,2.64,3.45,4.46,4.46,1.22,
1.22,0.32,0.29,0.5,0.32,0.32)
yy <- c(0.09,0.16,0.22,0.14,0.75,0.86,1.34,1.34,0.47,0.47,
0.22,0.23,0.26,0.16,0.16)
#' najprv spojnicove grafy
plot(zz, type = 'b')
#' najprv spojnicove grafy
plot(zz, type = 'b', xlab = 'cas', ylab = 'hodnota', col = 'blue')
#' najprv spojnicove grafy
plot(zz, type = 'b', xlab = 'cas', ylab = 'hodnota', col = 'blue', ylim = c(0, 600))
lines(xx*100)
lines(xx*100, type = 'b')
lines(xx*100, type = 'b', col = 'green')
lines(xx*100, type = 'b', col = 'red')
lines(yy*100, type = 'b', col = 'green')
lm5 <- lm(zz~xx+yy)
summary(lm5)
#' Nezavislych premennych moze byt viac a mame vybrat len tie, ktore
#' naozaj vysvetluju zavislu premennu, navyse sa nezavisle mozu aj
#' ovplyvnovat (kolinearita, setrit). Zakladny postup na vyukovych
#' datach z kniznice datarium, marketing, su to vydaje na reklamu
#' v mediach youtube, facebook, newspaper a k tomu objem predaja sales
library(datarium)
install.packages('datarium')
#' Nezavislych premennych moze byt viac a mame vybrat len tie, ktore
#' naozaj vysvetluju zavislu premennu, navyse sa nezavisle mozu aj
#' ovplyvnovat (kolinearita, setrit). Zakladny postup na vyukovych
#' datach z kniznice datarium, marketing, su to vydaje na reklamu
#' v mediach youtube, facebook, newspaper a k tomu objem predaja sales
library(datarium)
head(marketing)
#' Najprv grafy, aby sme odhalili strukturu dat, teraz nas zaujimaju
#' iba dvojice sales+ vzdy kazda nezavisla
pairs(marketing)
#' korelacie a grafy
library(corplot)
install.packages('corplot')
#' korelacie a grafy
library(corplot)
#' korelacie a grafy
library('corplot')
install.packages('corplot')
#' korelacie a grafy
library('corplot')
#' korelacie a grafy
library('corrplot')
k <- cor(marketing)
corrplot.mixed(k)
#' regresna funkcia, vyhodnotenie kvality
lm6 <- lm(sales~., data=marketing)
summary(lm6)
#' Vidime, ze premennu newspaper mozno vylucit z mnoziny bazovych
#' premennych, prepocitame regresiu
lm7 <- lm(sales~youtube + facebook, data = marketing)
summary(lm7)
summary(lm6)
summary(lm7)
AIC(lm6, lm7)
#' Kedze nezavislych premennych moze byt viac a nie vsetky patria
#' do regresie, preto je vhodne pouzit prikaz standardneho balika step,
#' predtym regresia pre vsetky premenne
step(lm6)
#' este mame k dispozicii
library(leaps)
install.packages('leaps')
#' este mame k dispozicii aj napr. kniznicu leaps
library(leaps)
vyber <- regsubsets(sales~., marketing)
vyber
summary(vyber)
vyber2 <- regsubsets(sales~., marketing, nbest = 2)
sum
summary(vyber2)
summary(vyber2)$bic
#'# Logisticka regresia
#' Objekty klasifikujeme do dvoch skupin, ma danu vlastnost Y=1,
#' nema danu vlastnost Y=0. Modelujeme P(Y=1). Vezmime priklad z prednasky.
#' Priklad Na klientovi banky sledujeme dva znaky, vzdelanie X=0, nema vs,
#' X=1 ma vs a ci ma problem splatit uver, Y=1 - ma problem splatit, nema
#' problem Y = 0. Model bude vyzerat
library(latexpdf)
#' $$P(Y=1)=\frac{1}{1+e^{-b_0-b_1 x}}$$
banka <- readxl::read_xlsx(path = 'data/banka.xlsx')
head(banka)
#' kontingencna tabulka znakov
table(banka$vzdelanie, banka$problem)
logit <- glm(problem~., data=banka, family=binomial)
summary(logit)
summary(logit)$coef
#' Nakreslime data aj logisticku krivku, nie je velmi informacny graf
b0 <- logit$coefficients[1]
b0
b1 <- logit$coefficients[2]
b1
xx <- seq(0, 1, 0.1)
xx
yy <- 1/(1+exp(-b0-b1*xx))
yy
plot(problem~vzdelanie, data = banka)
lines(xx, yy)
library(mlbench)
install.packages('mlbench')
library(caret)
library(mlbench)
library(ggplot2)
library(ggplot2)
library(lattice)
library(corrplot)
library(Amelia)
data('PimaIndiansDiabetes2')
head(PimaIndiansDiabetes2)
cors(PimaIndiansDiabetes2)
cor(PimaIndiansDiabetes2)
#' Vyuzijeme vykove data, ktore pochadzaju z narodneho ustavu diabetu .. ma
#' 8 vysvetlujucich premennych a jednu zavislu vsvetlovanu premennu cukrovka
#' pos, neg, vyhodime vektory s chybajucimi datami
missmap(PimaIndiansDiabetes2)
diab <- na.omit(PimaIndiansDiabetes2)
diab
nrow(diab)
#' pozrieme na strukturu dat, najprv krabicove grafy pre nezavisle premenne
par(mfrow=c(2,4))
for(i in 1:8){boxplot(diab[,i], main=names(diab)[i])}
for(i in 1:8){boxplot(diab[,i], main=names(diab)[i])}
#' pozrieme na strukturu dat, najprv krabicove grafy pre nezavisle premenne
par(mfrow=c(2,4))
#' pozrieme na strukturu dat, najprv krabicove grafy pre nezavisle premenne
par(mfrow=c(2,4))
for(i in 1:8){boxplot(diab[,i], main=names(diab)[i])}
#' lepsie su krabicove grafy rozdelene na cukrovku-ano, nie
lapply(1:8, function(i)
boxplot(diab[,i]~diab$diabetes, main=names(diab)[i]))
#' lepsie su krabicove grafy rozdelene na cukrovku-ano, nie
invisible(lapply(1:8, function(i)
boxplot(diab[,i]~diab$diabetes, main=names(diab)[i])))
par(mfrow=c(1,1))
pairs(diab, col=diab$diabetes)
#' najprv vezmime iba jednu premennu glucose, prelozme logisticku krivku
logit1 <- glm(diabetes~glucose, data=diab, family=binomial)
logit1$coefficients
b0 <- logit1$coefficients[1]
b1 <- logit1$coefficients[2]
plot(function(x) 1/(1+exp(-b0-b1*x)), xlim=c(-10, 10))
plot(function(x) 1/(1+exp(-b0-b1*x)), xlim=c(50, 200))
min(diab$glucose)
max(diab$glucose)
#' este sme zabudli na korelacie medzi nezavislymi premennymi, moze problem,
#' ze navzajom koreluju, kolinearita
kk <- cor(diab[,1:8])
corrplot.mixed(kk)
#' urobime logisticku regresiu so vsetkymi nezavislymi premennymi
pimamodel <- glm(diabates~., data = diab, family = binomial)
#' urobime logisticku regresiu so vsetkymi nezavislymi premennymi
pimamodel <- glm(diabetes~., data = diab, family = binomial)
summary(pimamodel)
#' Niektore premenne nie je treba uvazovat v regresii, teraz to nebudeme
#' riesit, ideme vyhodnotit kvalitu regresie. Hosmer-Lemeshow test (test
#' dobrej zhody, ci ked rozdelime data do tried podla nejakeho pravidla
#' su empiricke a napocitane pocetnosti v zhode). H0 su rovnake, model je ok
library(glmtool)
#' Niektore premenne nie je treba uvazovat v regresii, teraz to nebudeme
#' riesit, ideme vyhodnotit kvalitu regresie. Hosmer-Lemeshow test (test
#' dobrej zhody, ci ked rozdelime data do tried podla nejakeho pravidla
#' su empiricke a napocitane pocetnosti v zhode). H0 su rovnake, model je ok
library(glmtoolbox)
install.packages(glmtoolbox)
install.packages('glmtoolbox')
#' Niektore premenne nie je treba uvazovat v regresii, teraz to nebudeme
#' riesit, ideme vyhodnotit kvalitu regresie. Hosmer-Lemeshow test (test
#' dobrej zhody, ci ked rozdelime data do tried podla nejakeho pravidla
#' su empiricke a napocitane pocetnosti v zhode). H0 su rovnake, model je ok
library(glmtoolbox)
hltest(pimamodel)
#' p hodnota < 0.05, zamietame H0, z tohto hladiska model nie je vhodny
#' likelihood Ratio test, porovnanie dvoch a viac modelov,
#' ak uvedieme len jeden model, tak porovname s konstanym modelom.
#' H0 je, ze medzi dvomi modelmi nie je rozdielu. Ak nie su rozdiely,
#' vyberiem jednoduchsi, ak su rozdiely, tak zostava vp latnosti zlozitejsi.
library(lmtest)
lrtest(logit)
lrtest(logit1)
lrtest(primamodel)
lrtest(pimamodel)
#' Zamietame H0, vyberame model 1
lrtest(pimamodel, logit1)
#' Aj tu zamietame H0, vyberame model 1
#' Kontingencne tabulky, aby sme zistili uspesnost predikcie cukrovky
#' podla modelu pimamodel
#' Najprv vypocitame pravdep. nastatia daneho
probs <- predict(pimamodel, type = 'response')
#' nasa medzna hodnota nech je 0.5 (cut point), vsetko nad je pozitivny,
#' vsetko pod je negativny
pred <- ifelse(probs > 0.5, 'pos', 'neg')
pred
table(diab$diabetes, pred)
mean(pred==diab$diabetes)
#' Uspesnost predpovede je 78%
#' ROC krivka, hodnota AUC, kniznica ROCR, ROCit, pROC
library(ROCit)
#' Napocitame pravdepodobnosti uz mame - probs, vytvorime objekt prediction
pr <- prediction(probs, diab$diabetes)
#' Uspesnost predpovede je 78%
#' ROC krivka, hodnota AUC, kniznica ROCR, ROCit, pROC
library(ROCR)
install.packages('ROCR')
#' Uspesnost predpovede je 78%
#' ROC krivka, hodnota AUC, kniznica ROCR, ROCit, pROC
library(ROCR)
#' Uspesnost predpovede je 78%
#' ROC krivka, hodnota AUC, kniznica ROCR, ROCit, pROC
library(ROCR)
#' Napocitame pravdepodobnosti uz mame - probs, vytvorime objekt prediction
pr <- prediction(probs, diab$diabetes)
pr
prf <- performance(pr, 'tpr', 'fpr')
plot(prf, colorize=T)
plot(prf, colorize=T, print.cutoffs.at=seq(0.1, by=0.2))
#' Este zratame obsah plochy pod krivkou
auc <- performance(probs, 'auc')
#' Este zratame obsah plochy pod krivkou
auc <- performance(pr, 'auc')
auc
auc@y.values
auc <- auc@y.values[[1]]
auc
auc <- round(auc, 2)
auc
legend(0.6, 0.4, auc, title='AUC')
legend(0.6, 0.4, auc, title='AUC', cex=1)
#' teraz ideme riesit otazku, kolko premennych je vysvetlujucich, aby
#' sme dostali co najoptimalnejsi model, pouzijeme proceduru step, MASS
library(MASS)
model.step <- step(pimamodel)
model.step1 <- stepAIC(pimamodel)
#' Likelihood Ratio test na porovnanie modelov
lrtest(pimamodel, model.step)
#' p hodnota >0.05, modely su porovnatelne, vyberame jednoduchsi
#' % uspesnosti, ROC, AUC
probs <- predict(model.step, type = 'response')
pred <- ifelse(probs > 0.5, 'pos', 'neg')
table(diab$diabetes, pred)
mean(pred==diab$diabetes)
#' p hodnota >0.05, modely su porovnatelne, vyberame jednoduchsi
#' % uspesnosti, ROC, AUC
probs <- predict(model.step, type = 'response')
pred <- ifelse(probs > 0.5, 'pos', 'neg')
table(diab$diabetes, pred)
mean(pred==diab$diabetes)
pr <- prediction(probs, diab$diabetes)
mean(pred==diab$diabetes)
pr <- prediction(probs, diab$diabetes)
prf <- performance(pr, 'tpr', 'fpr')
plot(prf, colorize=T)
plot(prf, colorize=T, print.cutoffs.at=seq(0.1, by=0.2))
#' Este zratame obsah plochy pod krivkou
auc <- performance(pr, 'auc')
auc <- auc@y.values[[1]]
auc <- round(auc, 2)
legend(0.6, 0.4, auc, title='AUC', cex=1)
